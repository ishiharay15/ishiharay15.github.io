<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Pruning Convolutional Network Demo | Yui A. Ishihara </title> <meta name="author" content="Yui A. Ishihara"> <meta name="description" content="Demo of pruning a simple CNN trained on MNIST dataset"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A4%96&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ishiharay15.github.io//projects/2_project/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Yui A. Ishihara </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Pruning Convolutional Network Demo</h1> <p class="post-description">Demo of pruning a simple CNN trained on MNIST dataset</p> </header> <article> <p>This Pruning Demo is adapted from the <strong>TinyML and Efficient Deep Learning Computing</strong> Course by Song Han at MIT.</p> <p>Contributions include visualization of magnitude based color scale of weights for all kernels of <code class="language-plaintext highlighter-rouge">conv1</code> layer of the model.</p> <p>This colab notebook provides code and a framework for the demo used in the Pruning lecture of <a href="https://efficientml.ai" rel="external nofollow noopener" target="_blank">MIT efficient AI course</a>.</p> <p>The neural network model definition and training schedule are adapted from <a href="https://github.com/pytorch/examples/blob/main/mnist/main.py" rel="external nofollow noopener" target="_blank">PyTorch example</a>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">PRETRAINED_WEIGHTS</span> <span class="o">=</span> <span class="sh">'</span><span class="s">pruning_demo_weights.pth</span><span class="sh">'</span>
</code></pre></div></div> <h1 id="setup">Setup</h1> <p>First, install the required packages and download the datasets and pretrained model. Here we use CIFAR10 dataset and VGG network which is the same as what we used in the Lab 0 tutorial.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Installing torchprofile...</span><span class="sh">'</span><span class="p">)</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">torchprofile</span> <span class="mi">1</span><span class="o">&gt;/</span><span class="n">dev</span><span class="o">/</span><span class="n">null</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">All required packages have been successfully installed!</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Installing torchprofile...
All required packages have been successfully installed!
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">copy</span>
<span class="kn">import</span> <span class="n">math</span>
<span class="kn">import</span> <span class="n">random</span>
<span class="kn">import</span> <span class="n">time</span>
<span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">OrderedDict</span><span class="p">,</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">Union</span><span class="p">,</span> <span class="n">List</span>

<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="n">torch.optim</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="n">torch.optim.lr_scheduler</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="n">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="n">torchprofile</span> <span class="kn">import</span> <span class="n">profile_macs</span>
<span class="kn">from</span> <span class="n">torchvision.datasets</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="n">torchvision.transforms</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="n">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="kn">from</span> <span class="n">torchprofile</span> <span class="kn">import</span> <span class="n">profile_macs</span>

<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">(),</span> \
<span class="sh">"</span><span class="s">The current runtime does not have CUDA support.</span><span class="sh">"</span> \
<span class="sh">"</span><span class="s">Please go to menu bar (Runtime - Change runtime type) and select GPU</span><span class="sh">"</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;torch._C.Generator at 0x7fab208dda90&gt;
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train</span><span class="p">(</span>
  <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span>
  <span class="n">dataloader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
  <span class="n">criterion</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span>
  <span class="n">optimizer</span><span class="p">:</span> <span class="n">Optimizer</span><span class="p">,</span>
  <span class="n">scheduler</span><span class="p">:</span> <span class="n">StepLR</span><span class="p">,</span>
  <span class="n">callbacks</span> <span class="o">=</span> <span class="bp">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>

  <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="c1"># Move the data from CPU to GPU
</span>    <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">.</span><span class="nf">cuda</span><span class="p">()</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span><span class="p">.</span><span class="nf">cuda</span><span class="p">()</span>

    <span class="c1"># Reset the gradients (from the last iteration)
</span>    <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>

    <span class="c1"># Forward inference
</span>    <span class="n">outputs</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>

    <span class="c1"># Backward propagation
</span>    <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>

    <span class="c1"># Update optimizer
</span>    <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">callbacks</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="n">callbacks</span><span class="p">:</span>
            <span class="nf">callback</span><span class="p">()</span>

  <span class="c1"># Update scheduler
</span>  <span class="n">scheduler</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@torch.inference_mode</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
  <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span>
  <span class="n">dataloader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
  <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>

  <span class="n">num_samples</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">num_correct</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sh">"</span><span class="s">eval</span><span class="sh">"</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                              <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">verbose</span><span class="p">):</span>
    <span class="c1"># Move the data from CPU to GPU
</span>    <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">.</span><span class="nf">cuda</span><span class="p">()</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span><span class="p">.</span><span class="nf">cuda</span><span class="p">()</span>

    <span class="c1"># Inference
</span>    <span class="n">outputs</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

    <span class="c1"># Convert logits to class indices
</span>    <span class="n">outputs</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Update metrics
</span>    <span class="n">num_samples</span> <span class="o">+=</span> <span class="n">targets</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">num_correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">outputs</span> <span class="o">==</span> <span class="n">targets</span><span class="p">).</span><span class="nf">sum</span><span class="p">()</span>

  <span class="nf">return </span><span class="p">(</span><span class="n">num_correct</span> <span class="o">/</span> <span class="n">num_samples</span> <span class="o">*</span> <span class="mi">100</span><span class="p">).</span><span class="nf">item</span><span class="p">()</span>
</code></pre></div></div> <p>Helper Functions (Flops, Model Size calculation, etc.)</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_model_macs</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="k">return</span> <span class="nf">profile_macs</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">get_sparsity</span><span class="p">(</span><span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    calculate the sparsity of the given tensor
        sparsity = #zeros / #elements = 1 - #nonzeros / #elements
    </span><span class="sh">"""</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="nf">float</span><span class="p">(</span><span class="n">tensor</span><span class="p">.</span><span class="nf">count_nonzero</span><span class="p">())</span> <span class="o">/</span> <span class="n">tensor</span><span class="p">.</span><span class="nf">numel</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">get_model_sparsity</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    calculate the sparsity of the given model
        sparsity = #zeros / #elements = 1 - #nonzeros / #elements
    </span><span class="sh">"""</span>
    <span class="n">num_nonzeros</span><span class="p">,</span> <span class="n">num_elements</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">():</span>
        <span class="n">num_nonzeros</span> <span class="o">+=</span> <span class="n">param</span><span class="p">.</span><span class="nf">count_nonzero</span><span class="p">()</span>
        <span class="n">num_elements</span> <span class="o">+=</span> <span class="n">param</span><span class="p">.</span><span class="nf">numel</span><span class="p">()</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="nf">float</span><span class="p">(</span><span class="n">num_nonzeros</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_elements</span>

<span class="k">def</span> <span class="nf">get_num_parameters</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">count_nonzero_only</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    calculate the total number of parameters of model
    :param count_nonzero_only: only count nonzero weights
    </span><span class="sh">"""</span>
    <span class="n">num_counted_elements</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">count_nonzero_only</span><span class="p">:</span>
            <span class="n">num_counted_elements</span> <span class="o">+=</span> <span class="n">param</span><span class="p">.</span><span class="nf">count_nonzero</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">num_counted_elements</span> <span class="o">+=</span> <span class="n">param</span><span class="p">.</span><span class="nf">numel</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">num_counted_elements</span>


<span class="k">def</span> <span class="nf">get_model_size</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">data_width</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">count_nonzero_only</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    calculate the model size in bits
    :param data_width: #bits per element
    :param count_nonzero_only: only count nonzero weights
    </span><span class="sh">"""</span>
    <span class="k">return</span> <span class="nf">get_num_parameters</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">count_nonzero_only</span><span class="p">)</span> <span class="o">*</span> <span class="n">data_width</span>

<span class="n">Byte</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">KiB</span> <span class="o">=</span> <span class="mi">1024</span> <span class="o">*</span> <span class="n">Byte</span>
<span class="n">MiB</span> <span class="o">=</span> <span class="mi">1024</span> <span class="o">*</span> <span class="n">KiB</span>
<span class="n">GiB</span> <span class="o">=</span> <span class="mi">1024</span> <span class="o">*</span> <span class="n">MiB</span>
</code></pre></div></div> <p>Define pruning functions.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">fine_grained_prune</span><span class="p">(</span><span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">sparsity</span> <span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    magnitude-based pruning for single tensor
    :param tensor: torch.(cuda.)Tensor, weight of conv/fc layer
    :param sparsity: float, pruning sparsity
        sparsity = #zeros / #elements = 1 - #nonzeros / #elements
    :return:
        torch.(cuda.)Tensor, mask for zeros
    </span><span class="sh">"""</span>
    <span class="n">sparsity</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="nf">max</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">sparsity</span><span class="p">),</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">sparsity</span> <span class="o">==</span> <span class="mf">1.0</span><span class="p">:</span>
        <span class="n">tensor</span><span class="p">.</span><span class="nf">zero_</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">sparsity</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones_like</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>

    <span class="n">num_elements</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="nf">numel</span><span class="p">()</span>

    <span class="n">num_zeros</span> <span class="o">=</span> <span class="nf">round</span><span class="p">(</span><span class="n">num_elements</span> <span class="o">*</span> <span class="n">sparsity</span><span class="p">)</span>
    <span class="n">importance</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="nf">abs</span><span class="p">()</span>
    <span class="n">threshold</span> <span class="o">=</span> <span class="n">importance</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="nf">kthvalue</span><span class="p">(</span><span class="n">num_zeros</span><span class="p">).</span><span class="n">values</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">gt</span><span class="p">(</span><span class="n">importance</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span>
    <span class="n">tensor</span><span class="p">.</span><span class="nf">mul_</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">mask</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">FineGrainedPruner</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">sparsity_dict</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">masks</span> <span class="o">=</span> <span class="n">FineGrainedPruner</span><span class="p">.</span><span class="nf">prune</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">sparsity_dict</span><span class="p">)</span>

    <span class="nd">@torch.no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">named_parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">masks</span><span class="p">:</span>
                <span class="n">param</span> <span class="o">*=</span> <span class="n">self</span><span class="p">.</span><span class="n">masks</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>

    <span class="nd">@staticmethod</span>
    <span class="nd">@torch.no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">prune</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">sparsity_dict</span><span class="p">):</span>
        <span class="n">masks</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">named_parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">param</span><span class="p">.</span><span class="nf">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span> <span class="c1"># we only prune conv and fc weights
</span>                <span class="k">if</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">sparsity_dict</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                    <span class="n">masks</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="nf">fine_grained_prune</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">sparsity_dict</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="nf">assert</span><span class="p">(</span><span class="n">sparsity_dict</span> <span class="o">&lt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">sparsity_dict</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">sparsity_dict</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">masks</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="nf">fine_grained_prune</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">sparsity_dict</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">masks</span>
</code></pre></div></div> <p>Load the MNIST dataset.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="p">.</span><span class="nc">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="p">.</span><span class="nc">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="p">.</span><span class="nc">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span>
    <span class="p">])</span>
<span class="n">to_image</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="p">(</span><span class="n">t</span><span class="o">*</span><span class="mf">0.3081</span><span class="o">+</span><span class="mf">0.1307</span><span class="p">).</span><span class="nf">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="p">).</span><span class="nf">numpy</span><span class="p">()</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">"</span><span class="s">train</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">test</span><span class="sh">"</span><span class="p">]:</span>
  <span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">]</span> <span class="o">=</span> <span class="nc">MNIST</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">data</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">train</span><span class="o">=</span><span class="p">(</span><span class="n">split</span> <span class="o">==</span> <span class="sh">"</span><span class="s">train</span><span class="sh">"</span><span class="p">),</span>
    <span class="n">download</span><span class="o">=</span><span class="p">(</span><span class="n">split</span> <span class="o">==</span> <span class="sh">"</span><span class="s">train</span><span class="sh">"</span><span class="p">),</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span>
  <span class="p">)</span>

<span class="n">dataloader</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">]:</span>
  <span class="n">dataloader</span><span class="p">[</span><span class="n">split</span><span class="p">]</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span>
    <span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">],</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span> <span class="k">if</span> <span class="n">split</span> <span class="o">==</span> <span class="sh">'</span><span class="s">train</span><span class="sh">'</span> <span class="k">else</span> <span class="mi">1000</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="p">(</span><span class="n">split</span> <span class="o">==</span> <span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">),</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">pin_memory</span><span class="o">=</span><span class="bp">True</span>
  <span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">demos</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">:</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">:</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">7</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">8</span><span class="p">:</span> <span class="mi">61</span><span class="p">,</span> <span class="mi">9</span><span class="p">:</span> <span class="mi">9</span><span class="p">}</span>
<span class="n">demo_inputs</span><span class="p">,</span> <span class="n">demo_images</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">digit</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">demos</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
    <span class="n">demo_inputs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">copy</span><span class="p">.</span><span class="nf">deepcopy</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">][</span><span class="n">index</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">demo_images</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nf">to_image</span><span class="p">(</span><span class="n">demo_inputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">demo_inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span><span class="n">demo_inputs</span><span class="p">).</span><span class="nf">cuda</span><span class="p">()</span>
</code></pre></div></div> <p>Create visualization for weight maps.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>

<span class="k">def</span> <span class="nf">visualize_weights</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">layer_name</span><span class="p">,</span> <span class="n">title</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Visualize the weights of a specific layer as a heatmap with weight values annotated.

    Args:
        model (torch.nn.Module): The PyTorch model.
        layer_name (str): The name of the layer to visualize.
        title (str): Title for the plot.
    </span><span class="sh">"""</span>

    <span class="n">weights</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">named_parameters</span><span class="p">())[</span><span class="n">layer_name</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>

    <span class="c1"># Check if it's a convolutional layer
</span>    <span class="k">if</span> <span class="n">weights</span><span class="p">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
        <span class="n">out_channels</span> <span class="o">=</span> <span class="n">weights</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">in_channels</span> <span class="o">=</span> <span class="n">weights</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># Create subplots for each kernel (visualize only one input channel per kernel)
</span>        <span class="n">cols</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span>
        <span class="n">rows</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">ceil</span><span class="p">(</span><span class="n">out_channels</span> <span class="o">/</span> <span class="n">cols</span><span class="p">))</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">cols</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">rows</span> <span class="o">*</span> <span class="mi">2</span><span class="p">))</span>
        <span class="n">fig</span><span class="p">.</span><span class="nf">suptitle</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">out_channels</span><span class="p">):</span>
            <span class="n">row</span><span class="p">,</span> <span class="n">col</span> <span class="o">=</span> <span class="nf">divmod</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">cols</span><span class="p">)</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">]</span> <span class="k">if</span> <span class="n">rows</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">axes</span><span class="p">[</span><span class="n">col</span><span class="p">]</span>
            <span class="n">kernel</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>

            <span class="c1"># Use absolute values for coloring but keep signed values for annotations, helps with visualizing weight magnitudes!
</span>            <span class="n">abs_kernel</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span>

            <span class="n">sns</span><span class="p">.</span><span class="nf">heatmap</span><span class="p">(</span>
                <span class="n">abs_kernel</span><span class="p">,</span>
                <span class="n">annot</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span>
                <span class="n">fmt</span><span class="o">=</span><span class="sh">"</span><span class="s">.2f</span><span class="sh">"</span><span class="p">,</span>
                <span class="n">cmap</span><span class="o">=</span><span class="n">sns</span><span class="p">.</span><span class="nf">light_palette</span><span class="p">(</span><span class="sh">"</span><span class="s">blue</span><span class="sh">"</span><span class="p">,</span> <span class="n">as_cmap</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
                <span class="n">cbar</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                <span class="n">square</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                <span class="n">ax</span><span class="o">=</span><span class="n">ax</span>
            <span class="p">)</span>
            <span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Kernel </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
            <span class="n">ax</span><span class="p">.</span><span class="nf">axis</span><span class="p">(</span><span class="sh">"</span><span class="s">off</span><span class="sh">"</span><span class="p">)</span>

        <span class="c1"># Turn off unused subplots
</span>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">rows</span> <span class="o">*</span> <span class="n">cols</span><span class="p">):</span>
            <span class="n">row</span><span class="p">,</span> <span class="n">col</span> <span class="o">=</span> <span class="nf">divmod</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">cols</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">rows</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">axes</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">].</span><span class="nf">axis</span><span class="p">(</span><span class="sh">"</span><span class="s">off</span><span class="sh">"</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">axes</span><span class="p">[</span><span class="n">col</span><span class="p">].</span><span class="nf">axis</span><span class="p">(</span><span class="sh">"</span><span class="s">off</span><span class="sh">"</span><span class="p">)</span>

        <span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">subplots_adjust</span><span class="p">(</span><span class="n">top</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">layer_name</span><span class="si">}</span><span class="s"> is not a convolutional layer.</span><span class="sh">"</span><span class="p">)</span>

</code></pre></div></div> <h1 id="neural-network-model">Neural Network Model</h1> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># 1 x 32 x 3 x 3 = 288 parameters
</span>        <span class="n">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># 32 x 64 x 3 x 3=18,432 paramters
</span>        <span class="n">self</span><span class="p">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">9216</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span> <span class="c1"># 9216 x 128 = 1,179,648 parameters
</span>        <span class="n">self</span><span class="p">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="c1"># 128 x 10 = 1,280 parameters
</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">Net</span><span class="p">().</span><span class="nf">cuda</span><span class="p">()</span>
</code></pre></div></div> <h1 id="lets-visualize-the-demo-images">Lets Visualize the Demo Images</h1> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">visualize</span><span class="p">(</span><span class="n">with_predictions</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">demo_inputs</span><span class="p">).</span><span class="nf">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">with_predictions</span> <span class="k">else</span> <span class="bp">None</span>
    <span class="k">for</span> <span class="n">digit</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">demos</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">digit</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">demo_images</span><span class="p">[</span><span class="n">digit</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">predictions</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">digit: </span><span class="si">{</span><span class="n">digit</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">digit: </span><span class="si">{</span><span class="n">digit</span><span class="si">}</span><span class="se">\n</span><span class="s">pred: </span><span class="si">{</span><span class="nf">int</span><span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="n">digit</span><span class="p">])</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">axis</span><span class="p">(</span><span class="sh">'</span><span class="s">off</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="nf">visualize</span><span class="p">()</span>
</code></pre></div></div> <p><img src="./Demo_Pruning_files/Demo_Pruning_24_0.png" alt="Pruning Visualization" width="100%"></p> <h1 id="pre-train-neural-network-on-mnist">Pre-train Neural Network on MNIST</h1> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Training
</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">lr_step_gamma</span> <span class="o">=</span> <span class="mf">0.7</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">5</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="nc">Adadelta</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">nll_loss</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="nc">StepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">lr_step_gamma</span><span class="p">)</span>

<span class="n">best_accuracy</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_checkpoint</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">()</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">],</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">is_best</span> <span class="o">=</span> <span class="n">accuracy</span> <span class="o">&gt;</span> <span class="n">best_accuracy</span>
    <span class="k">if</span> <span class="n">is_best</span><span class="p">:</span>
        <span class="n">best_checkpoint</span><span class="p">[</span><span class="sh">'</span><span class="s">state_dict</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">copy</span><span class="p">.</span><span class="nf">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">())</span>
        <span class="n">best_accuracy</span> <span class="o">=</span> <span class="n">accuracy</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">    Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">:</span><span class="o">&gt;</span><span class="mi">2</span><span class="n">d</span><span class="si">}</span><span class="s"> Accuracy </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">% / Best Accuracy: </span><span class="si">{</span><span class="n">best_accuracy</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">%</span><span class="sh">'</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">=&gt; loading best checkpoint</span><span class="sh">"</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">best_checkpoint</span><span class="p">[</span><span class="sh">'</span><span class="s">state_dict</span><span class="sh">'</span><span class="p">])</span>
<span class="n">recover_model</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">model</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">best_checkpoint</span><span class="p">[</span><span class="sh">'</span><span class="s">state_dict</span><span class="sh">'</span><span class="p">])</span>

</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lr</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">lr_step_gamma</span> <span class="o">=</span> <span class="mf">0.7</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">nll_loss</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="nc">Adadelta</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">nll_loss</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="nc">StepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">lr_step_gamma</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load model
</span><span class="n">model</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">PRETRAINED_WEIGHTS</span><span class="p">))</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;ipython-input-24-22b05c65e864&gt;:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(PRETRAINED_WEIGHTS))
</code></pre></div></div> <h1 id="lets-first-evaluate-the-accuracy-and-model-size-of-dense-model">Lets First Evaluate the Accuracy and Model Size of Dense Model</h1> <p>Lets first evaluate the accuracy and model size of this model.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dense_model_accuracy</span> <span class="o">=</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">])</span>
<span class="n">dense_model_size</span> <span class="o">=</span> <span class="nf">get_model_size</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">dense model has accuracy=</span><span class="si">{</span><span class="n">dense_model_accuracy</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">%</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">dense model has size=</span><span class="si">{</span><span class="n">dense_model_size</span><span class="o">/</span><span class="n">MiB</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> MiB</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">visualize</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dense model has accuracy=98.98%
dense model has size=4.58 MiB
</code></pre></div></div> <p><img src="./Demo_Pruning_files/Demo_Pruning_31_2.png" alt="Pruning Visualization" width="100%"></p> <h1 id="visualize-the-conv1-weights-before-pruning">Visualize the conv1 Weights Before Pruning</h1> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Visualize conv1
</span><span class="nf">visualize_weights</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="sh">"</span><span class="s">conv1.weight</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">conv1 Weights Before Pruning</span><span class="sh">"</span><span class="p">)</span>

</code></pre></div></div> <p><img src="./Demo_Pruning_files/Demo_Pruning_33_0.png" alt="Pruning Visualization" width="100%"></p> <h1 id="lets-prune-the-model-and-re-evaluate-the-accuracy">Lets Prune the Model and Re-Evaluate the Accuracy.</h1> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sparsity</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">pruner</span> <span class="o">=</span> <span class="nc">FineGrainedPruner</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">sparsity</span><span class="p">)</span>
<span class="n">pruner</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">sparse_model_accuracy</span> <span class="o">=</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">])</span>
<span class="n">sparse_model_size</span> <span class="o">=</span> <span class="nf">get_model_size</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">count_nonzero_only</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">sparsity</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s">% sparse model has accuracy=</span><span class="si">{</span><span class="n">sparse_model_accuracy</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">%</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">sparsity</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s">% sparse model has size=</span><span class="si">{</span><span class="n">sparse_model_size</span><span class="o">/</span><span class="n">MiB</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> MiB, </span><span class="sh">"</span>
      <span class="sa">f</span><span class="sh">"</span><span class="s">which is </span><span class="si">{</span><span class="n">dense_model_size</span><span class="o">/</span><span class="n">sparse_model_size</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">X smaller than </span><span class="sh">"</span>
      <span class="sa">f</span><span class="sh">"</span><span class="s">the </span><span class="si">{</span><span class="n">dense_model_size</span><span class="o">/</span><span class="n">MiB</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> MiB dense model</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">visualize</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>90.0% sparse model has accuracy=19.11%
90.0% sparse model has size=0.46 MiB, which is 9.98X smaller than the 4.58 MiB dense model
</code></pre></div></div> <p><img src="./Demo_Pruning_files/Demo_Pruning_35_2.png" alt="Pruning Visualization" width="100%"></p> <h1 id="now-re-visualize-the-conv1-weights-after-pruning">Now, Re-Visualize the conv1 Weights After Pruning!</h1> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">visualize_weights</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="sh">"</span><span class="s">conv1.weight</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">conv1 Weights After Pruning</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p><img src="./Demo_Pruning_files/Demo_Pruning_37_0.png" alt="Pruning Visualization" width="100%"></p> <h1 id="lets-fine-tune-the-pruned-model-to-get-higher-accuracy">Lets Fine-tune the Pruned Model to Get Higher Accuracy</h1> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num_finetune_epochs</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">SGD</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">lr_scheduler</span><span class="p">.</span><span class="nc">CosineAnnealingLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">num_finetune_epochs</span><span class="p">)</span>

<span class="n">best_sparse_checkpoint</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">()</span>
<span class="n">best_sparse_accuracy</span> <span class="o">=</span> <span class="mi">0</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Finetuning Fine-grained Pruned Sparse Model</span><span class="sh">'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_finetune_epochs</span><span class="p">):</span>
    <span class="c1"># At the end of each train iteration, we have to apply the pruning mask
</span>    <span class="c1">#    to keep the model sparse during the training
</span>    <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">],</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span>
          <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="k">lambda</span><span class="p">:</span> <span class="n">pruner</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="n">model</span><span class="p">)])</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">is_best</span> <span class="o">=</span> <span class="n">accuracy</span> <span class="o">&gt;</span> <span class="n">best_sparse_accuracy</span>
    <span class="k">if</span> <span class="n">is_best</span><span class="p">:</span>
        <span class="n">best_sparse_checkpoint</span><span class="p">[</span><span class="sh">'</span><span class="s">state_dict</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">copy</span><span class="p">.</span><span class="nf">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">())</span>
        <span class="n">best_sparse_accuracy</span> <span class="o">=</span> <span class="n">accuracy</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">    Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s"> Sparse Accuracy </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">% / Best Sparse Accuracy: </span><span class="si">{</span><span class="n">best_sparse_accuracy</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">%</span><span class="sh">'</span><span class="p">)</span>

</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Finetuning Fine-grained Pruned Sparse Model

    Epoch 1 Sparse Accuracy 97.89% / Best Sparse Accuracy: 97.89%
    Epoch 2 Sparse Accuracy 98.42% / Best Sparse Accuracy: 98.42%
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">best_sparse_checkpoint</span><span class="p">[</span><span class="sh">'</span><span class="s">state_dict</span><span class="sh">'</span><span class="p">])</span>
<span class="n">sparse_model_accuracy</span> <span class="o">=</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">])</span>
<span class="n">sparse_model_size</span> <span class="o">=</span> <span class="nf">get_model_size</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">count_nonzero_only</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">sparsity</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s">% sparse model has accuracy=</span><span class="si">{</span><span class="n">sparse_model_accuracy</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">%</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">sparsity</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s">% sparse model has size=</span><span class="si">{</span><span class="n">sparse_model_size</span><span class="o">/</span><span class="n">MiB</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> MiB, </span><span class="sh">"</span>
      <span class="sa">f</span><span class="sh">"</span><span class="s">which is </span><span class="si">{</span><span class="n">dense_model_size</span><span class="o">/</span><span class="n">sparse_model_size</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">X smaller than </span><span class="sh">"</span>
      <span class="sa">f</span><span class="sh">"</span><span class="s">the </span><span class="si">{</span><span class="n">dense_model_size</span><span class="o">/</span><span class="n">MiB</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> MiB dense model</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">visualize</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>90.0% sparse model has accuracy=98.42%
90.0% sparse model has size=0.46 MiB, which is 9.98X smaller than the 4.58 MiB dense model
</code></pre></div></div> <p><img src="./Demo_Pruning_files/Demo_Pruning_40_2.png" alt="Pruning Visualization" width="100%"></p> <h1 id="visualize-the-conv1-weights-after-fine-tuning">Visualize the conv1 Weights After Fine-Tuning!</h1> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">visualize_weights</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="sh">"</span><span class="s">conv1.weight</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">conv1 Weights After Fine-Tuning</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p><img src="./Demo_Pruning_files/Demo_Pruning_42_0.png" alt="Pruning Visualization" width="100%"></p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0">  Copyright 2025 Yui A. Ishihara. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: January 25, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>