<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Benchmarking Low-Light Image Enhancement (LLIE) and Restoration | Yui A. Ishihara </title> <meta name="author" content="Yui A. Ishihara"> <meta name="description" content="Assessing effectiveness of Low-Light Image Enhancement as a pre-processing method for computer vision tasks"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8E%80&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ishiharay15.github.io//projects/1_project/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Yui A. Ishihara </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Benchmarking Low-Light Image Enhancement (LLIE) and Restoration</h1> <p class="post-description">Assessing effectiveness of Low-Light Image Enhancement as a pre-processing method for computer vision tasks</p> </header> <article> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/yolo_oppo_results-480.webp 480w,/assets/img/yolo_oppo_results-800.webp 800w,/assets/img/yolo_oppo_results-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/yolo_oppo_results.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Project Results" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Night-Vision Restoration Pipeline! ðŸ”¦ </div> <h1 id="project-overview">Project Overview:</h1> <p>This project focuses on enhancing image and video quality in low-light environments, particularly targeting the improvement of object detection in security camera footage. By addressing the challenges of lack of color and increased noise in low-light imagery, our solution aims to significantly enhance object recognition in dimly lit settings. Through the integration of noise reduction and color enhancement processes, coupled with object detection algorithms like YOLO, we aim to generate color-enhanced images with accurately detected object classes, thereby facilitating improved surveillance capabilities for security applications. To assess the efficacy of our methodology, we plan to employ metrics such as Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), and Mean Average Precision (mAP) to evaluate image quality improvements quantitatively. Additionally, we consider the compatibility of different image enhancement models with the YOLO object detection framework, ensuring optimal performance and accuracy in detecting objects within the reconstructed images. Our comprehensive approach aims to not only enhance image quality but also to optimize object detection capabilities, contributing to advancements in security surveillance effectiveness, and comprehension in low-light conditions.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/pipeline-480.webp 480w,/assets/img/pipeline-800.webp 800w,/assets/img/pipeline-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/pipeline.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Project Pipeline" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Night-Vision Restoration Pipeline! ðŸŒ™ </div> <h1 id="benchmarked-models">Benchmarked Models:</h1> <p><strong><a href="https://github.com/LiuYunlong99/RQ-LLIE" rel="external nofollow noopener" target="_blank">Low-Light Image Enhancement with Multi-stage Residue Quantization (RQ-LLIE)</a>:</strong> RQ-LLIE proposes a brightness-aware network for low-light image enhancement that uses normal-light priors to improve results. The method combines normal-light and low-light features and employs a brightness-aware attention module.\</p> <p><strong><a href="https://github.com/caiyuanhao1998/Retinexformer" rel="external nofollow noopener" target="_blank">Retinexformer</a>:</strong> The Retinexformer model is a One-stage Retinex-based Framework (ORF) for LLIE, using an Illumination-Guided Transformer (IGT) to model non-local interactions and restore image corruption.\</p> <p><strong><a href="https://github.com/TaoWangzj/LLFormer" rel="external nofollow noopener" target="_blank">LLFormer</a>:</strong> LLFormer is a transformer-based method that uses axis-based multi-head self-attention and cross-layer attention fusion to reduce complexity and improve performance.\</p> <p><strong><a href="https://github.com/jinnh/GSAD" rel="external nofollow noopener" target="_blank">Global Structure-Aware Diffusion Process for Low-Light Image Enhancement (GSAD)</a>:</strong> GSAD introduces a diffusion-based method for low-light image enhancement, incorporating curvature regularization and uncertainty-guided techniques to improve the enhancement process.</p> <h1 id="benchmarking-metrics">Benchmarking Metrics:</h1> <p><strong>Peak Signal-to-Noise Ratio (PSNR):</strong> PSNR quantifies image quality by comparing the original and enhanced images, focusing on greyscale intensity and RGB channels independently. It provides a measure of how closely the color and intensity of the two images align.\</p> <p><strong>Structural Similarity Index (SSIM):</strong> SSIM evaluates similarity in luminance, contrast, and structure between original and enhanced images. This metric offers a broader assessment of visual fidelity, often providing a more accurate representation than PSNR.\</p> <p><strong>Mean Average Precision (mAP):</strong> mAP calculates the average precision of model detections across all classes, using a defined accuracy threshold for object detection. This metric summarizes the modelâ€™s overall detection performance.\</p> <h1 id="results">Results:</h1> <p>Our results demonstrate that the benchmarked models effectively enhance brightness, color, and reduce noise in low-light images, leading to improved object detection capabilities. By applying different enhancement techniquesâ€”RetinexFormer, Global Structure-Aware, LLFlow, and RQ-LLIEâ€”each model showed distinct results in enhancing test images, leading to more accurate detection of objects using YOLOv5. Analysis of the <a href="https://github.com/cs-chan/Exclusively-Dark-Image-Dataset" rel="external nofollow noopener" target="_blank">Exclusively Dark (ExDark) Image Dataset</a> reveals that the enhanced images enable YOLOv5 to detect objects with greater precision across various classes, compared to unenhanced images.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/enhancement_results-480.webp 480w,/assets/img/enhancement_results-800.webp 800w,/assets/img/enhancement_results-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/enhancement_results.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Enhancement Results" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Night-Vision Restoration Results! ðŸ”¦ </div> <p>We also tested our models on the <a href="https://github.com/dvlab-research/SDSD" rel="external nofollow noopener" target="_blank">Seeing Dynamic Scene in the Dark (SDSD)</a> dataset, which contains low-light videos, for further testing to validate the modelsâ€™ efficacy in dynamic, real-world scenarios. The results below highlights the potential of integrating low-light enhancement with object detection frameworks, promising advancements in security and surveillance applications.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/yolo_oppo_results-480.webp 480w,/assets/img/yolo_oppo_results-800.webp 800w,/assets/img/yolo_oppo_results-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/yolo_oppo_results.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Video Enhancement Results" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> YOLO Video Test Results! ðŸŽ¬ </div> </article> <h2>References</h2> <div class="publications"> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> Â© Copyright 2025 Yui A. Ishihara. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>